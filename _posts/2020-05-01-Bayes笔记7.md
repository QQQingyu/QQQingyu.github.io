---
layout:     post                    # 使用的布局（不需要改）
title:      Bayes笔记七( Markov Chain Monte Carlo)               # 标题
subtitle:   Series notes of SDSC6003 course. #副标题
date:       2020-05-01              # 时间
author:     Qingyu                      # 作者
header-img: img/post-bg-unix-linux.jpg  #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Bayes Theory
---

##### Markov Chain Monte Carlo (MCMC)

It is often difficult or impossible to <u>find the marginal posterior distributions</u> of $\theta_{i}$ based on $g(\theta | x)$ analytically. Moreover, $\theta$ is often high-dimensional, which precludes simple numerical methods such as numerical integration to obtain summary measures of $g(\theta | x)$ from $L(\theta), q(\theta)$

A class of methods based on simulating a Markov chain that converges to $g(\theta | x)$ are available and the methods, collectively called **MCMC methods** do not require knowledge of the normalizing constant of $g(\theta | x)$. This represents a breakthrough in Bayesian computation. The most common MCMC methods are <u>based on the idea of specifying a reversible Markov chain with $g(\theta | x)$ as stationary distribution</u>.

##### Metropolis-Hastings algorithm

The Metropolis-Hastings algorithm is as follows:

0. Initialization: set $t=0$ and specify $\theta^{(0)}$
1. Let $\theta^{(t)}$ be the current state of the chain. Generate a sample $\tilde{\theta}$ from $q\left(\theta | \theta^{(t)}\right),$ where $q$ is called the **proposal distribution**.
2. Calculate the acceptance probability:
   $\alpha\left(\theta^{(t)}, \tilde{\theta}\right)=\min \left\{\frac{\left.L(\widetilde{\theta}) g(\tilde{\theta}) q\left(\theta^{(t)}\right) \tilde{\theta}\right)}{L\left(\theta^{(t)}\right) g\left(\theta^{(t)}\right) q\left(\tilde{\theta} | \theta^{(t)}\right)}, 1\right\}$
3. Set $\theta^{(t+1)}=\tilde{\theta}$ with probability $\alpha\left(\theta^{(t)}, \tilde{\theta}\right)$ and $\operatorname{set} \theta^{(t+1)}=\theta^{(t)}$ with
   probability $1-\alpha\left(\theta^{(t)}, \tilde{\theta}\right)$
4. Set $t=t+1$ and return to Step 1

- The Metropolis-Hastings algorithm generates a reversible Markov chain with stationary distribution $g(\theta | x)$ .

- Under some conditions (aperiodic and irreducibility with respect to $g(\theta | x)$ ), the marginal distribution of $\theta^{(t)}$ converges to $g(\theta | x)$ as $t \rightarrow \infty$.

- One can estimate $E(e(\theta) | x)$ with $N^{-1} \sum_{t=1}^{N} e\left(\theta^{(t)}\right)$ since the latter will converge to the former almost surely.

- Common choices of $q$ :

  - A normal distribution (or some other distribution) centered at $\theta^{(t)}$ - random walk Metropolis-Hastings algorithm, e.g., $\theta^{\prime} | \theta \sim N(\theta, \Psi)$

  2. A fixed distribution - independence Metropolis-Hastings algorithm, e.g. $\theta^{\prime} | \theta \sim N(\mu, \Psi)$

2. The <u>acceptance rate for a random walk Metropolis-Hastings algorithm should be around 23%</u> when $\theta$ has more than one component as this rate has been demonstrated to be optimal for a multivariate normal posterior and multivariate normal random walk proposal.

##### Selecting the proposal distribution

For problems in which an appropriate proposal is not obvious.

- Set $M^{*}$ equal to the <u>posterior mode</u> found by an optimization algorithm applied to minimize $-\ln [L(\theta) g(\theta)] .$ Compute a numerical estimate of the Hessian matrix of $-\ln [L(\theta) g(\theta)]$ at $\theta=M^{*} .$ Set $\Sigma^{*}$ equal the inverse of this Hessian matrix.

- Start the Metropolis-Hastings algorithm at $\theta^{(0)}=M^{*}$.
- Set the proposal distribution $q\left(\theta^{\prime} | \theta\right)$ to be $N\left(\theta, \delta\left(\frac{2.38^{2}}{k}\right) \Sigma^{*}\right),$ where $k$ is the dimension of $\theta$ and $\delta=1$
- If the acceptance rate is far above $23 \%,$ we can adjust $\delta$ upwards. If the acceptance rate is far below $23 \%$, we can adjust $\delta$ downwards.

##### Gibbs sampling

Consider a multiparameter problem with the posterior distribution $g\left(\theta_{1}, \ldots, \theta_{k} | x\right) \propto L\left(\theta_{1}, \ldots, \theta_{k}\right) g\left(\theta_{1}, \ldots, \theta_{k}\right)$. By dropping all factors on the right-hand-side that do not depend on $\theta_{i},$ we obtain $g\left(\theta_{i} | x, \theta_{-i}\right)$ up to a proportionality constant, where $\theta_{-i}=\left(\theta_{1}, \ldots, \theta_{i-1}, \theta_{i+1}, \ldots, \theta_{k}\right)$. The distributions represented by the PDFs $g\left(\theta_{i} | x, \theta_{-i}\right), i=1, \ldots, k$ are called **full conditional distributions**.

- For many problems, sampling from the $g\left(\theta_{i} | x, \theta_{-i}\right)^{\prime}$ 's is easier not only because they are univariate distributions but also because they are typically from known families of distributions.

Gibbs sampling is as follows:
Initialize with $\theta_{1}^{0}, \ldots, \theta_{k}^{0}$ (perhaps the prior mode/mean). Set $j=1$ $* \mathrm{At}$ iteration $j,$ do the following:
$\operatorname{Draw} \theta_{1}^{j} \operatorname{from} g\left(\theta_{1} | x, \theta_{2}^{j-1}, \ldots, \theta_{k}^{j-1}\right)$
$\operatorname{Draw} \theta_{i}^{j}$ from $g\left(\theta_{i} | x, \theta_{1}^{j}, \ldots, \theta_{i-1}^{j}, \theta_{i+1}^{j-1}, \ldots, \theta_{k}^{j-1}\right)$
:
$\operatorname{Draw} \theta_{k}^{j}$ from $g\left(\theta_{k} | x, \theta_{1}^{j}, \ldots, \theta_{k-1}^{j}\right)$
Set $j=j+1$ and return to $^{*}$

- The Gibbs samples are $\theta^{j}=\left(\theta_{1}^{j}, \ldots, \theta_{k}^{j}\right), j=N_{0}+1, \ldots, N,$ where $N_{0}$ is the number of burn-in samples, and $N$ is a large number. This means that the Markov chain $\theta^{1}, \theta^{2}, \ldots$ is judged to have converged to the stationary distribution after the $N_{0}$ th iteration.

##### Change-point problem

Suppose that $X_{1}, \ldots, X_{m}$ are iid $N\left(\mu, \sigma^{2}\right), X_{m+1}, \ldots, X_{n}$ are iid $N\left(\mu^{\prime}, \sigma^{2}\right),$ where $n=20$ and $m \in\{11, \ldots, 19\}$ is an unknown. Suppose we know that $\sigma^{2}=1$ and the data is -0.22,0.38,-0.86,-1.04,-0.56,-0.63,0.05,-1.82,-1.55,0.1 0.46,-0.37,1.31,-1.12,-0.32,0.58,1.95,3.08,2.07,2.4

- The likelihood is $L\left(\mu, \mu^{\prime}, m\right)=\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(x_{i}-\right.\right. \left.\mu)^{2}\right] \prod_{i=m+1}^{n} \frac{1}{\sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(x_{i}-\mu^{\prime}\right)^{2}\right]$
  Suppose we employ a prior $g\left(\mu, \mu^{\prime}, m\right) \propto I(m \in\{11, \ldots, 19\})$
- Then, the posterior is $g\left(\mu, \mu^{\prime}, m | x\right) \propto \exp \left[-\frac{m}{2}(\bar{x}-\mu)^{2}\right] \exp \left[-\frac{n-m}{2}\left(\bar{x}^{\prime}-\mu^{\prime}\right)^{2}\right] \exp \left[-\frac{1}{2} \sum_{i=1}^{m}\left(x_{i}-\bar{x}\right)^{2}-\right.$
  $\left.\frac{1}{2} \sum_{i=m+1}^{n}\left(x_{i}-\bar{x}^{\prime}\right)^{2}\right] I(m \in\{11, \ldots, 19\})$
  where $\bar{x}=m^{-1} \sum_{i=1}^{m} x_{i}$ and $\bar{x}^{\prime}=(n-m)^{-1} \sum_{i=m+1}^{n} x_{i}$

- We see that the full conditional distributions are
  $g\left(\mu | \mu^{\prime}, m, x\right) \propto \exp \left[-\frac{m}{2}(\bar{x}-\mu)^{2}\right] \Rightarrow \mu | \mu^{\prime}, m, x \sim N\left(\bar{x}, \frac{1}{m}\right)$
  $g\left(\mu^{\prime} | \mu, m, x\right) \propto \exp \left[-\frac{n-m}{2}\left(\bar{x}^{\prime}-\mu^{\prime}\right)^{2}\right] \Rightarrow \mu^{\prime} | \mu, m, x \sim N\left(\bar{x}^{\prime}, \frac{1}{n-m}\right)$
  $g\left(m | \mu, \mu^{\prime}, x\right) \propto \exp \left[-\frac{m}{2}(\bar{x}-\mu)^{2}\right] \exp \left[-\frac{n-m}{2}\left(\bar{x}^{\prime}-\mu^{\prime}\right)^{2}\right] \exp \left[-\frac{1}{2} \sum_{i=1}^{m}\left(x_{i}-\right.\right.$
  $\left.\bar{x})^{2}-\frac{1}{2} \sum_{i=m+1}^{n}\left(x_{i}-\bar{x}^{\prime}\right)^{2}\right] I(m \in\{11, \ldots, 19\})$

